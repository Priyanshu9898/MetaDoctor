{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1432479,"sourceType":"datasetVersion","datasetId":839140}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n#         print(os.path.join(dirname, filename))\n        pass\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications import (VGG16, VGG19, ResNet50, InceptionV3, MobileNetV2,\n                                DenseNet121, Xception)\nfrom keras.applications.efficientnet import (EfficientNetB0, EfficientNetB1, EfficientNetB2,\n                                             EfficientNetB3, EfficientNetB4, EfficientNetB5,\n                                             EfficientNetB6, EfficientNetB7, preprocess_input as efficientnet_preprocess_input)\nfrom keras.applications.vgg16 import preprocess_input as vgg16_preprocess_input\nfrom keras.applications.vgg19 import preprocess_input as vgg19_preprocess_input\nfrom keras.applications.resnet50 import preprocess_input as resnet50_preprocess_input\nfrom keras.applications.inception_v3 import preprocess_input as inceptionv3_preprocess_input\nfrom keras.applications.mobilenet_v2 import preprocess_input as mobilenetv2_preprocess_input\nfrom keras.applications.densenet import preprocess_input as densenet_preprocess_input\nfrom keras.applications.xception import preprocess_input as xception_preprocess_input\nfrom keras.layers import GlobalAveragePooling2D, Dense\nfrom keras.models import Model\nfrom keras.layers import BatchNormalization, MaxPooling2D, Dropout, Flatten, Dense\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define your data directories\ntrain_folder = '/kaggle/input/chest-ctscan-images/Data/train'\nvalid_folder = '/kaggle/input/chest-ctscan-images/Data/valid'\ntest_folder = '/kaggle/input/chest-ctscan-images/Data/test'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model configurations\nnum_classes = 4\nbatch_size = 32\nepochs = 100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Map model names to their function, preprocess_input, and input_shape\nmodel_info = {\n    'VGG16': (VGG16, vgg16_preprocess_input, (224, 224, 3)),\n    'VGG19': (VGG19, vgg19_preprocess_input, (224, 224, 3)),\n    'ResNet50': (ResNet50, resnet50_preprocess_input, (224, 224, 3)),\n    'InceptionV3': (InceptionV3, inceptionv3_preprocess_input, (299, 299, 3)),\n    'MobileNetV2': (MobileNetV2, mobilenetv2_preprocess_input, (224, 224, 3)),\n    'DenseNet121': (DenseNet121, densenet_preprocess_input, (224, 224, 3)),\n    'Xception': (Xception, xception_preprocess_input, (299, 299, 3)),\n    'EfficientNetB0': (EfficientNetB0, efficientnet_preprocess_input, (224, 224, 3)),\n    'EfficientNetB1': (EfficientNetB1, efficientnet_preprocess_input, (240, 240, 3)),\n    'EfficientNetB2': (EfficientNetB2, efficientnet_preprocess_input, (260, 260, 3)),\n    'EfficientNetB3': (EfficientNetB3, efficientnet_preprocess_input, (300, 300, 3)),\n    'EfficientNetB5': (EfficientNetB5, efficientnet_preprocess_input, (224, 224, 3)), \n    'EfficientNetB4': (EfficientNetB4, efficientnet_preprocess_input, (224, 224, 3)),\n    'EfficientNetB6': (EfficientNetB6, efficientnet_preprocess_input, (300, 300, 3)),\n    'EfficientNetB7': (EfficientNetB7, efficientnet_preprocess_input, (300, 300, 3)),\n}\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model_name, num_classes, train_folder, valid_folder, epochs, batch_size):\n    model_class, preprocess_input, input_shape = model_info[model_name]\n\n    # Data generators with model-specific preprocessing\n    train_datagen = ImageDataGenerator(\n        dtype='float32',\n        preprocessing_function=preprocess_input,\n        rotation_range=10,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        vertical_flip=False\n    )\n    val_datagen = ImageDataGenerator(dtype='float32', preprocessing_function=preprocess_input)\n    test_datagen = ImageDataGenerator(\n        dtype='float32',\n        preprocessing_function=preprocess_input,\n    )\n    train_generator = train_datagen.flow_from_directory(\n        train_folder,\n        target_size=input_shape[:2],\n        batch_size=batch_size,\n        class_mode='categorical'\n    )\n    validation_generator = val_datagen.flow_from_directory(\n        valid_folder,\n        target_size=input_shape[:2],\n        batch_size=batch_size,\n        class_mode='categorical'\n    )\n    \n    # Model creation\n    base_model = model_class(weights='imagenet', include_top=False, input_shape=input_shape)\n    x = base_model.output\n    x = BatchNormalization()(x)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n    x = Flatten()(x)\n    x = Dense(1024, activation='relu')(x)\n    x = Dropout(0.3)(x)\n    x = Dense(512, activation='relu')(x)\n    x = Dropout(0.3)(x)\n    x = Dense(256, activation='relu')(x)\n    x = Dropout(0.3)(x)\n    predictions = Dense(num_classes, activation='softmax')(x)\n    model = Model(inputs=base_model.input, outputs=predictions)\n\n    # Compile the model\n    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n    \n    # Define Callbacks\n    checkpoint = ModelCheckpoint(filepath=f'{model_name}_model.h5',\n                                 monitor='val_accuracy',\n                                 mode='max',\n                                 save_best_only=True,\n                                 verbose=1)\n\n    earlystop = EarlyStopping(monitor='val_accuracy',\n                              min_delta=0.001,\n                              patience=15,\n                              restore_best_weights=True)\n\n    reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                                  factor=0.1,\n                                  patience=10,\n                                  verbose=1,\n                                  min_delta=0.0001,\n                                  min_lr=0.0001)\n\n    callbacks = [checkpoint, earlystop, reduce_lr]\n\n    # Train the model\n    history = model.fit(train_generator, validation_data=validation_generator, callbacks=callbacks, epochs=epochs, steps_per_epoch=np.ceil(train_generator.samples/batch_size), validation_steps=np.ceil(validation_generator.samples/batch_size))\n    \n    # Plot training history\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title(f'{model_name} Model Accuracy')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='upper left')\n\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title(f'{model_name} Model Loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='upper left')\n\n    # Save the plot\n    plt.savefig(f'{model_name}_accuracy_loss_plot.png')\n    plt.close()\n    \n    return model\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train and save each model\nfor model_name in model_info.keys():\n    print(f\"Training {model_name}...\")\n    model = train_model(model_name, num_classes, train_folder, valid_folder, epochs, batch_size)\n#     model.save(f'{model_name}_model.h5')\n    print(f\"{model_name} model training completed and saved.\")\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn import metrics\nimport tensorflow.keras\nimport os\n\n# Function to evaluate the model and generate necessary metrics\ndef evaluate_model(model, test_generator, model_name):\n    # Evaluate the model\n    loss, accuracy = model.evaluate(test_generator, steps=np.ceil(test_generator.samples/test_generator.batch_size))\n\n    # Generate predictions\n    test_generator.reset()\n    predictions = model.predict(test_generator, steps=np.ceil(test_generator.samples/test_generator.batch_size))\n    predicted_classes = np.argmax(predictions, axis=1)\n    true_classes = test_generator.classes\n\n    # Compute confusion matrix and classification report\n    cm = confusion_matrix(true_classes, predicted_classes)\n    report = classification_report(true_classes, predicted_classes, target_names=test_generator.class_indices.keys(), output_dict=True)\n\n    # Extract overall precision, recall, and f1-score\n    precision = report['weighted avg']['precision']\n    recall = report['weighted avg']['recall']\n    f1_score = report['weighted avg']['f1-score']\n\n    return accuracy, loss, precision, recall, f1_score, cm\n\n# Path to save the CSV file\ncsv_file = 'model_results.csv'\n\n# Check if the CSV file exists. If not, create it with appropriate headers\nif not os.path.exists(csv_file):\n    pd.DataFrame(columns=['Model', 'Accuracy', 'Loss', 'Precision', 'Recall', 'F1 Score']).to_csv(csv_file, index=False)\n\n    \n    # Function to plot and save confusion matrix as heatmap\ndef plot_and_save_confusion_matrix(cm, model_name, class_names):\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title(f'Confusion Matrix for {model_name}')\n    plt.savefig(f'{model_name}_confusion_matrix.png')\n    \n# Evaluate each model and append results to the CSV file\nfor model_name in model_info.keys():\n    \n    model_class, preprocess_input, input_shape = model_info[model_name]\n    \n    test_datagen = ImageDataGenerator(\n        dtype='float32',\n        preprocessing_function=preprocess_input,\n    )\n    \n    test_generator = test_datagen.flow_from_directory(\n        test_folder,\n        target_size=input_shape[:2],\n        batch_size=batch_size,\n        class_mode='categorical',\n        shuffle = False,\n    )\n    \n    model = tensorflow.keras.models.load_model(f'{model_name}_model.h5')\n    accuracy, loss, precision, recall, f1_score, cm = evaluate_model(model, test_generator, model_name)\n\n    # Append results to the CSV\n    new_row = pd.DataFrame([[model_name, accuracy, loss, precision, recall, f1_score]], columns=['Model', 'Accuracy', 'Loss', 'Precision', 'Recall', 'F1 Score'])\n    pd.concat([pd.read_csv(csv_file), new_row]).to_csv(csv_file, index=False)\n\n    # Print Confusion Matrix\n    print(f'Confusion Matrix for {model_name}:')\n    print(cm)\n    # Plot and save Confusion Matrix as Heatmap\n    plot_and_save_confusion_matrix(cm, model_name, list(test_generator.class_indices.keys()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}