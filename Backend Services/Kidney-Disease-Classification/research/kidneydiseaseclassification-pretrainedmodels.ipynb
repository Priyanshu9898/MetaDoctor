{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2764486,"sourceType":"datasetVersion","datasetId":1686903}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n#         print(os.path.join(dirname, filename))\n        pass\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-27T11:24:23.443567Z","iopub.execute_input":"2023-12-27T11:24:23.444278Z","iopub.status.idle":"2023-12-27T11:24:30.398685Z","shell.execute_reply.started":"2023-12-27T11:24:23.444242Z","shell.execute_reply":"2023-12-27T11:24:30.397839Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications import (VGG16, VGG19, ResNet50, InceptionV3, MobileNetV2,\n                                DenseNet121, Xception)\nfrom keras.applications.efficientnet import (EfficientNetB0, EfficientNetB1, EfficientNetB2,\n                                             EfficientNetB3, EfficientNetB4, EfficientNetB5,\n                                             EfficientNetB6, EfficientNetB7, preprocess_input as efficientnet_preprocess_input)\nfrom keras.applications.vgg16 import preprocess_input as vgg16_preprocess_input\nfrom keras.applications.vgg19 import preprocess_input as vgg19_preprocess_input\nfrom keras.applications.resnet50 import preprocess_input as resnet50_preprocess_input\nfrom keras.applications.inception_v3 import preprocess_input as inceptionv3_preprocess_input\nfrom keras.applications.mobilenet_v2 import preprocess_input as mobilenetv2_preprocess_input\nfrom keras.applications.densenet import preprocess_input as densenet_preprocess_input\nfrom keras.applications.xception import preprocess_input as xception_preprocess_input\nfrom keras.layers import GlobalAveragePooling2D, Dense\nfrom keras.models import Model\nfrom keras.layers import BatchNormalization, MaxPooling2D, Dropout, Flatten, Dense\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nimport tensorflow as tf\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom sklearn.metrics import confusion_matrix, accuracy_score, recall_score, f1_score, precision_score","metadata":{"execution":{"iopub.status.busy":"2023-12-27T11:24:30.400180Z","iopub.execute_input":"2023-12-27T11:24:30.400579Z","iopub.status.idle":"2023-12-27T11:24:34.769541Z","shell.execute_reply.started":"2023-12-27T11:24:30.400553Z","shell.execute_reply":"2023-12-27T11:24:34.768573Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Constants\nDATA_DIR = \"/kaggle/input/ct-kidney-dataset-normal-cyst-tumor-and-stone/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone\"\n","metadata":{"execution":{"iopub.status.busy":"2023-12-27T11:24:34.770730Z","iopub.execute_input":"2023-12-27T11:24:34.771240Z","iopub.status.idle":"2023-12-27T11:24:34.776028Z","shell.execute_reply.started":"2023-12-27T11:24:34.771212Z","shell.execute_reply":"2023-12-27T11:24:34.774945Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Model configurations\nnum_classes = 4\nbatch_size = 32\nepochs = 50","metadata":{"execution":{"iopub.status.busy":"2023-12-27T11:24:34.778981Z","iopub.execute_input":"2023-12-27T11:24:34.779274Z","iopub.status.idle":"2023-12-27T11:24:34.795619Z","shell.execute_reply.started":"2023-12-27T11:24:34.779250Z","shell.execute_reply":"2023-12-27T11:24:34.794727Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Map model names to their function, preprocess_input, and input_shape\nmodel_info = {\n    'VGG16': (VGG16, vgg16_preprocess_input, (224, 224, 3)),\n    'VGG19': (VGG19, vgg19_preprocess_input, (224, 224, 3)),\n    'ResNet50': (ResNet50, resnet50_preprocess_input, (224, 224, 3)),\n    'InceptionV3': (InceptionV3, inceptionv3_preprocess_input, (299, 299, 3)),\n    'MobileNetV2': (MobileNetV2, mobilenetv2_preprocess_input, (224, 224, 3)),\n    'DenseNet121': (DenseNet121, densenet_preprocess_input, (224, 224, 3)),\n    'Xception': (Xception, xception_preprocess_input, (299, 299, 3)),\n    'EfficientNetB0': (EfficientNetB0, efficientnet_preprocess_input, (224, 224, 3)),\n    'EfficientNetB1': (EfficientNetB1, efficientnet_preprocess_input, (240, 240, 3)),\n    'EfficientNetB2': (EfficientNetB2, efficientnet_preprocess_input, (260, 260, 3)),\n    'EfficientNetB3': (EfficientNetB3, efficientnet_preprocess_input, (300, 300, 3)),\n    'EfficientNetB4': (EfficientNetB4, efficientnet_preprocess_input, (224, 224, 3))),\n    'EfficientNetB5': (EfficientNetB5, efficientnet_preprocess_input, (224, 224, 3))),\n    'EfficientNetB6': (EfficientNetB6, efficientnet_preprocess_input, (224, 224, 3))),\n    'EfficientNetB7': (EfficientNetB7, efficientnet_preprocess_input, (224, 224, 3)))\n}","metadata":{"execution":{"iopub.status.busy":"2023-12-27T11:24:34.796707Z","iopub.execute_input":"2023-12-27T11:24:34.797083Z","iopub.status.idle":"2023-12-27T11:24:34.804896Z","shell.execute_reply.started":"2023-12-27T11:24:34.797024Z","shell.execute_reply":"2023-12-27T11:24:34.804071Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def train_model(model_name, num_classes, data_dir, epochs, batch_size):\n    model_class, preprocess_input, input_shape = model_info[model_name]\n\n    # Load and preprocess the data using tf.data\n    train_dataset = image_dataset_from_directory(\n        data_dir,\n        validation_split=0.2,\n        subset=\"training\",\n        seed=123,\n        image_size=input_shape[:2],\n        batch_size=batch_size,\n        label_mode='categorical'\n    )\n\n    validation_dataset = image_dataset_from_directory(\n        data_dir,\n        validation_split=0.2,\n        subset=\"validation\",\n        seed=123,\n        image_size=input_shape[:2],\n        batch_size=batch_size,\n        label_mode='categorical'\n    )\n\n    # Define the image augmentation layer\n    data_augmentation = tf.keras.Sequential([\n        tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n        tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n        tf.keras.layers.experimental.preprocessing.RandomZoom(0.1),\n        tf.keras.layers.experimental.preprocessing.RandomTranslation(height_factor=0.1, width_factor=0.1)\n    ])\n\n    # Apply augmentation and preprocessing only to the training dataset\n    train_dataset = train_dataset.map(lambda x, y: (data_augmentation(x, training=True), y))\n    train_dataset = train_dataset.map(lambda x, y: (preprocess_input(x), y))\n\n    # Apply only preprocessing to the validation dataset\n    validation_dataset = validation_dataset.map(lambda x, y: (preprocess_input(x), y))\n\n    # AUTOTUNE\n    AUTOTUNE = tf.data.experimental.AUTOTUNE\n    train_dataset = train_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n    validation_dataset = validation_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n\n\n    # Model creation\n    base_model = model_class(weights='imagenet', include_top=False, input_shape=input_shape)\n    x = base_model.output\n    x = BatchNormalization()(x)\n    x = Flatten()(x)\n    x = Dense(1024, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    x = Dense(512, activation='relu')(x)\n    x = Dropout(0.3)(x)\n    x = Dense(256, activation='relu')(x)\n    x = Dropout(0.3)(x)\n    predictions = Dense(num_classes, activation='softmax')(x)\n    model = Model(inputs=base_model.input, outputs=predictions)\n    \n    # Compile the model\n    METRICS = [\n        'accuracy',\n        tf.keras.metrics.Precision(name='precision'),\n        tf.keras.metrics.Recall(name='recall')\n    ]\n\n    # Compile the model\n    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=METRICS)\n    \n    \n    # Define Callbacks\n    checkpoint = ModelCheckpoint(filepath=f'{model_name}_model.h5',\n                                 monitor='val_accuracy',\n                                 mode='max',\n                                 save_best_only=True,\n                                 verbose=1)\n\n    earlystop = EarlyStopping(monitor='val_accuracy',\n                              min_delta=0.001,\n                              patience=15,\n                              restore_best_weights=True)\n\n    reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                                  factor=0.1,\n                                  patience=10,\n                                  verbose=1,\n                                  min_delta=0.0001,\n                                  min_lr=0.0001)\n\n    callbacks = [checkpoint, earlystop, reduce_lr]\n    \n    # Train the model\n    history = model.fit(\n        train_dataset,\n        epochs=epochs,\n        validation_data=validation_dataset,\n        callbacks=callbacks\n    )\n    \n    # Plot training history\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title(f'{model_name} Model Accuracy')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='upper left')\n\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title(f'{model_name} Model Loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='upper left')\n\n    # Save the plot\n    plt.savefig(f'{model_name}_accuracy_loss_plot.png')\n    plt.close()\n    \n    fig, ax = plt.subplots(2,2 , figsize=(8, 10))\n    ax = ax.ravel()\n\n    for i, met in enumerate(['precision', 'recall', 'accuracy', 'loss']):\n        ax[i].plot(history.history[met])\n        ax[i].plot(history.history['val_' + met])\n        ax[i].set_title('Model {}'.format(met))\n        ax[i].set_xlabel('epochs')\n        ax[i].set_ylabel(met)\n        ax[i].legend(['train', 'val'])\n    fig.savefig(f'{model_name}_metrics.png')\n    \n    print(f\"{model_name}_performance...\")\n    loss, accuracy, precision, recall = model.evaluate(validation_dataset)\n    print(f\"Validation Loss: {loss}\")\n    print(f\"Validation Accuracy: {accuracy}\")\n    print(f\"Validation Precision: {precision}\")\n    print(f\"Validation Recall: {recall}\")\n    \n    val_dataset = validation_dataset.unbatch().batch(1)\n    true_labels = []\n    predictions = []\n    for x, y in val_dataset:\n        true_labels.append(np.argmax(y.numpy(), axis=1))\n        predictions.append(np.argmax(model.predict(x), axis=1))\n\n    true_labels = np.concatenate(true_labels)\n    predictions = np.concatenate(predictions)\n\n    # Confusion Matrix\n    cm = confusion_matrix(true_labels, predictions)\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Cyst', 'Normal', 'Stone', 'Tumor'],yticklabels=['Cyst', 'Normal', 'Stone', 'Tumor'])\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title(f'Confusion Matrix for {model_name}')\n    plt.savefig(f'{model_name}_confusion_matrix.png')\n\n    # Metrics\n    print(f\"{model_name}_performance Metrics...\")\n    accuracy = accuracy_score(true_labels, predictions)\n    precision = precision_score(true_labels, predictions, average='weighted')\n    recall = recall_score(true_labels, predictions, average='weighted')\n    f1score = f1_score(true_labels, predictions, average='weighted')\n    \n    print(\"accuracy\", accuracy)\n    print(\"precision\", precision)\n    print(\"recall\", recall)\n    print(\"f1-score\", f1score)\n\n    # Save metrics to CSV file\n    csv_file = 'model_results.csv'\n    new_row = pd.DataFrame([[model_name, accuracy, precision, recall, f1score]], columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n    if not os.path.exists(csv_file):\n        new_row.to_csv(csv_file, index=False)\n    else:\n        pd.concat([pd.read_csv(csv_file), new_row]).to_csv(csv_file, index=False)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-12-27T11:24:34.806384Z","iopub.execute_input":"2023-12-27T11:24:34.806651Z","iopub.status.idle":"2023-12-27T11:24:34.838005Z","shell.execute_reply.started":"2023-12-27T11:24:34.806627Z","shell.execute_reply":"2023-12-27T11:24:34.837054Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Train and save each model\nfor model_name in model_info.keys():\n    print(f\"Training {model_name}...\")\n    model = train_model(model_name, num_classes, DATA_DIR, epochs, batch_size)\n#     model.save(f'{model_name}_model.h5')\n    print(f\"{model_name} model training completed and saved.\")\n    print(\"=============================================================================\")","metadata":{"execution":{"iopub.status.busy":"2023-12-27T11:24:34.839271Z","iopub.execute_input":"2023-12-27T11:24:34.840002Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Training VGG16...\nFound 12446 files belonging to 4 classes.\nUsing 9957 files for training.\nFound 12446 files belonging to 4 classes.\nUsing 2489 files for validation.\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58889256/58889256 [==============================] - 0s 0us/step\nEpoch 1/50\n312/312 [==============================] - ETA: 0s - loss: 1.2137 - accuracy: 0.5755 - precision: 0.6390 - recall: 0.4620\nEpoch 1: val_accuracy improved from -inf to 0.41382, saving model to VGG16_model.h5\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n","output_type":"stream"},{"name":"stdout","text":"312/312 [==============================] - 251s 732ms/step - loss: 1.2137 - accuracy: 0.5755 - precision: 0.6390 - recall: 0.4620 - val_loss: 1.8086 - val_accuracy: 0.4138 - val_precision: 0.5082 - val_recall: 0.3973 - lr: 0.0010\nEpoch 2/50\n312/312 [==============================] - ETA: 0s - loss: 0.8985 - accuracy: 0.6682 - precision: 0.7340 - recall: 0.5621\nEpoch 2: val_accuracy improved from 0.41382 to 0.45440, saving model to VGG16_model.h5\n312/312 [==============================] - 141s 453ms/step - loss: 0.8985 - accuracy: 0.6682 - precision: 0.7340 - recall: 0.5621 - val_loss: 1.6454 - val_accuracy: 0.4544 - val_precision: 0.5756 - val_recall: 0.3961 - lr: 0.0010\nEpoch 3/50\n312/312 [==============================] - ETA: 0s - loss: 0.7542 - accuracy: 0.6866 - precision: 0.7528 - recall: 0.6053\nEpoch 6: val_accuracy did not improve from 0.67658\n312/312 [==============================] - 140s 448ms/step - loss: 0.7542 - accuracy: 0.6866 - precision: 0.7528 - recall: 0.6053 - val_loss: 37.0993 - val_accuracy: 0.6750 - val_precision: 0.7221 - val_recall: 0.6452 - lr: 0.0010\nEpoch 7/50\n312/312 [==============================] - ETA: 0s - loss: 0.7217 - accuracy: 0.6978 - precision: 0.7625 - recall: 0.6263\nEpoch 7: val_accuracy improved from 0.67658 to 0.71113, saving model to VGG16_model.h5\n312/312 [==============================] - 141s 451ms/step - loss: 0.7217 - accuracy: 0.6978 - precision: 0.7625 - recall: 0.6263 - val_loss: 0.7817 - val_accuracy: 0.7111 - val_precision: 0.7517 - val_recall: 0.6689 - lr: 0.0010\nEpoch 8/50\n312/312 [==============================] - ETA: 0s - loss: 0.6620 - accuracy: 0.7211 - precision: 0.7749 - recall: 0.6567\nEpoch 8: val_accuracy improved from 0.71113 to 0.75010, saving model to VGG16_model.h5\n312/312 [==============================] - 141s 451ms/step - loss: 0.6620 - accuracy: 0.7211 - precision: 0.7749 - recall: 0.6567 - val_loss: 7.7774 - val_accuracy: 0.7501 - val_precision: 0.7734 - val_recall: 0.7336 - lr: 0.0010\nEpoch 9/50\n312/312 [==============================] - ETA: 0s - loss: 0.6141 - accuracy: 0.7543 - precision: 0.7944 - recall: 0.7012\nEpoch 9: val_accuracy did not improve from 0.75010\n312/312 [==============================] - 139s 446ms/step - loss: 0.6141 - accuracy: 0.7543 - precision: 0.7944 - recall: 0.7012 - val_loss: 1.8330 - val_accuracy: 0.6806 - val_precision: 0.6952 - val_recall: 0.6597 - lr: 0.0010\nEpoch 10/50\n312/312 [==============================] - ETA: 0s - loss: 0.5935 - accuracy: 0.7617 - precision: 0.7998 - recall: 0.7132\nEpoch 10: val_accuracy did not improve from 0.75010\n312/312 [==============================] - 139s 446ms/step - loss: 0.5935 - accuracy: 0.7617 - precision: 0.7998 - recall: 0.7132 - val_loss: 7.4750 - val_accuracy: 0.4444 - val_precision: 0.4573 - val_recall: 0.4299 - lr: 0.0010\nEpoch 11/50\n312/312 [==============================] - ETA: 0s - loss: 0.5616 - accuracy: 0.7689 - precision: 0.8050 - recall: 0.7276\nEpoch 11: val_accuracy improved from 0.75010 to 0.75733, saving model to VGG16_model.h5\n312/312 [==============================] - 140s 449ms/step - loss: 0.5616 - accuracy: 0.7689 - precision: 0.8050 - recall: 0.7276 - val_loss: 0.8058 - val_accuracy: 0.7573 - val_precision: 0.7743 - val_recall: 0.7401 - lr: 0.0010\nEpoch 12/50\n312/312 [==============================] - ETA: 0s - loss: 0.5302 - accuracy: 0.7886 - precision: 0.8218 - recall: 0.7568\nEpoch 12: val_accuracy did not improve from 0.75733\n312/312 [==============================] - 139s 446ms/step - loss: 0.5302 - accuracy: 0.7886 - precision: 0.8218 - recall: 0.7568 - val_loss: 4.7718 - val_accuracy: 0.5275 - val_precision: 0.5362 - val_recall: 0.5211 - lr: 0.0010\nEpoch 13/50\n312/312 [==============================] - ETA: 0s - loss: 0.4914 - accuracy: 0.8058 - precision: 0.8314 - recall: 0.7731\nEpoch 13: val_accuracy improved from 0.75733 to 0.77300, saving model to VGG16_model.h5\n312/312 [==============================] - 140s 449ms/step - loss: 0.4914 - accuracy: 0.8058 - precision: 0.8314 - recall: 0.7731 - val_loss: 0.8393 - val_accuracy: 0.7730 - val_precision: 0.8038 - val_recall: 0.7553 - lr: 0.0010\nEpoch 14/50\n312/312 [==============================] - ETA: 0s - loss: 0.4244 - accuracy: 0.8334 - precision: 0.8555 - recall: 0.8074\nEpoch 14: val_accuracy did not improve from 0.77300\n312/312 [==============================] - 139s 446ms/step - loss: 0.4244 - accuracy: 0.8334 - precision: 0.8555 - recall: 0.8074 - val_loss: 1.4937 - val_accuracy: 0.7541 - val_precision: 0.7724 - val_recall: 0.7433 - lr: 0.0010\nEpoch 15/50\n312/312 [==============================] - ETA: 0s - loss: 0.3985 - accuracy: 0.8489 - precision: 0.8681 - recall: 0.8248\nEpoch 15: val_accuracy improved from 0.77300 to 0.77903, saving model to VGG16_model.h5\n312/312 [==============================] - 140s 450ms/step - loss: 0.3985 - accuracy: 0.8489 - precision: 0.8681 - recall: 0.8248 - val_loss: 0.8888 - val_accuracy: 0.7790 - val_precision: 0.7905 - val_recall: 0.7686 - lr: 0.0010\nEpoch 16/50\n312/312 [==============================] - ETA: 0s - loss: 0.3582 - accuracy: 0.8551 - precision: 0.8714 - recall: 0.8369\nEpoch 16: val_accuracy did not improve from 0.77903\n312/312 [==============================] - 139s 445ms/step - loss: 0.3582 - accuracy: 0.8551 - precision: 0.8714 - recall: 0.8369 - val_loss: 272.4407 - val_accuracy: 0.7296 - val_precision: 0.7405 - val_recall: 0.7256 - lr: 0.0010\nEpoch 17/50\n312/312 [==============================] - ETA: 0s - loss: 0.3537 - accuracy: 0.8692 - precision: 0.8855 - recall: 0.8528\nEpoch 17: val_accuracy improved from 0.77903 to 0.80956, saving model to VGG16_model.h5\n312/312 [==============================] - 140s 448ms/step - loss: 0.3537 - accuracy: 0.8692 - precision: 0.8855 - recall: 0.8528 - val_loss: 0.7331 - val_accuracy: 0.8096 - val_precision: 0.8192 - val_recall: 0.7955 - lr: 0.0010\nEpoch 18/50\n312/312 [==============================] - ETA: 0s - loss: 0.3019 - accuracy: 0.8855 - precision: 0.8984 - recall: 0.8717\nEpoch 18: val_accuracy did not improve from 0.80956\n312/312 [==============================] - 139s 445ms/step - loss: 0.3019 - accuracy: 0.8855 - precision: 0.8984 - recall: 0.8717 - val_loss: 1.5342 - val_accuracy: 0.8035 - val_precision: 0.8188 - val_recall: 0.7843 - lr: 0.0010\nEpoch 19/50\n312/312 [==============================] - ETA: 0s - loss: 0.2962 - accuracy: 0.8887 - precision: 0.9013 - recall: 0.8759\nEpoch 19: val_accuracy improved from 0.80956 to 0.84693, saving model to VGG16_model.h5\n312/312 [==============================] - 139s 446ms/step - loss: 0.2962 - accuracy: 0.8887 - precision: 0.9013 - recall: 0.8759 - val_loss: 0.7993 - val_accuracy: 0.8469 - val_precision: 0.8498 - val_recall: 0.8453 - lr: 0.0010\nEpoch 20/50\n312/312 [==============================] - ETA: 0s - loss: 0.2601 - accuracy: 0.9078 - precision: 0.9163 - recall: 0.8963\nEpoch 20: val_accuracy did not improve from 0.84693\n312/312 [==============================] - 139s 445ms/step - loss: 0.2601 - accuracy: 0.9078 - precision: 0.9163 - recall: 0.8963 - val_loss: 1.1807 - val_accuracy: 0.7955 - val_precision: 0.8024 - val_recall: 0.7915 - lr: 0.0010\nEpoch 21/50\n 37/312 [==>...........................] - ETA: 1:54 - loss: 0.1979 - accuracy: 0.9181 - precision: 0.9309 - recall: 0.9096","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}