{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2764486,"sourceType":"datasetVersion","datasetId":1686903}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n#         print(os.path.join(dirname, filename))\n        pass\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-26T16:17:42.842823Z","iopub.execute_input":"2023-12-26T16:17:42.843184Z","iopub.status.idle":"2023-12-26T16:18:01.251280Z","shell.execute_reply.started":"2023-12-26T16:17:42.843152Z","shell.execute_reply":"2023-12-26T16:18:01.249971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install joblib","metadata":{"execution":{"iopub.status.busy":"2023-12-26T16:18:01.253052Z","iopub.execute_input":"2023-12-26T16:18:01.253721Z","iopub.status.idle":"2023-12-26T16:18:15.040093Z","shell.execute_reply.started":"2023-12-26T16:18:01.253649Z","shell.execute_reply":"2023-12-26T16:18:15.038784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\nimport time\nimport joblib\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2023-12-26T16:18:15.042328Z","iopub.execute_input":"2023-12-26T16:18:15.042838Z","iopub.status.idle":"2023-12-26T16:18:15.861457Z","shell.execute_reply.started":"2023-12-26T16:18:15.042789Z","shell.execute_reply":"2023-12-26T16:18:15.860054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport time\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom skimage.feature import hog","metadata":{"execution":{"iopub.status.busy":"2023-12-26T16:18:15.866885Z","iopub.execute_input":"2023-12-26T16:18:15.867488Z","iopub.status.idle":"2023-12-26T16:18:15.965966Z","shell.execute_reply.started":"2023-12-26T16:18:15.867450Z","shell.execute_reply":"2023-12-26T16:18:15.965097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the dataset directory and classes\ndataset_dir = \"/kaggle/input/ct-kidney-dataset-normal-cyst-tumor-and-stone/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone\"\nclasses = ['Cyst', 'Normal', 'Stone', 'Tumor']","metadata":{"execution":{"iopub.status.busy":"2023-12-26T16:18:15.967401Z","iopub.execute_input":"2023-12-26T16:18:15.968138Z","iopub.status.idle":"2023-12-26T16:18:15.974234Z","shell.execute_reply.started":"2023-12-26T16:18:15.968070Z","shell.execute_reply":"2023-12-26T16:18:15.972782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to load images and extract features\ndef load_images_and_features(dataset_dir, classes):\n    images = []\n    labels = []\n    for label, class_name in enumerate(classes):\n        class_dir = os.path.join(dataset_dir, class_name)\n        for filename in os.listdir(class_dir):\n            img_path = os.path.join(class_dir, filename)\n            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n            img = cv2.resize(img, (128, 128))  # Resize for consistency\n\n            # Extract HOG features\n            features, _ = hog(img, orientations=8, pixels_per_cell=(16, 16),\n                  cells_per_block=(1, 1), visualize=True)\n\n            \n            images.append(features)\n            labels.append(label)\n\n    return np.array(images), np.array(labels)","metadata":{"execution":{"iopub.status.busy":"2023-12-26T16:18:15.976354Z","iopub.execute_input":"2023-12-26T16:18:15.976875Z","iopub.status.idle":"2023-12-26T16:18:15.993229Z","shell.execute_reply.started":"2023-12-26T16:18:15.976817Z","shell.execute_reply":"2023-12-26T16:18:15.991976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the dataset\nX, y = load_images_and_features(dataset_dir, classes)","metadata":{"execution":{"iopub.status.busy":"2023-12-26T16:18:15.994649Z","iopub.execute_input":"2023-12-26T16:18:15.995421Z","iopub.status.idle":"2023-12-26T16:24:51.163139Z","shell.execute_reply.started":"2023-12-26T16:18:15.995381Z","shell.execute_reply":"2023-12-26T16:24:51.161992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-12-26T16:24:51.164740Z","iopub.execute_input":"2023-12-26T16:24:51.165188Z","iopub.status.idle":"2023-12-26T16:24:51.196881Z","shell.execute_reply.started":"2023-12-26T16:24:51.165147Z","shell.execute_reply":"2023-12-26T16:24:51.196015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Expanding the classifiers list\nclassifiers = {\n    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n    \"SVM\": SVC(kernel='linear', probability=True),\n    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n    \"Naive Bayes\": GaussianNB(),\n    \"Decision Tree\": DecisionTreeClassifier(),\n    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100),\n    \"AdaBoost\": AdaBoostClassifier(n_estimators=100),\n    \"Extra Trees\": ExtraTreesClassifier(n_estimators=100)\n}","metadata":{"execution":{"iopub.status.busy":"2023-12-26T16:24:51.198116Z","iopub.execute_input":"2023-12-26T16:24:51.198640Z","iopub.status.idle":"2023-12-26T16:24:51.204634Z","shell.execute_reply.started":"2023-12-26T16:24:51.198609Z","shell.execute_reply":"2023-12-26T16:24:51.203737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DataFrame to store results\nresults_df = pd.DataFrame(columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"Training Time (s)\"])\n\n# Train, evaluate each classifier, and save results\nfor name, clf in classifiers.items():\n    start_time = time.time()\n    clf.fit(X_train, y_train)\n    training_time = time.time() - start_time\n    \n    print(f\"Total Training time for {name}: \", training_time)\n\n    y_pred = clf.predict(X_test)\n    \n    # Save the trained model\n    model_filename = f\"{name.replace(' ', '_')}_model.joblib\"\n    joblib.dump(clf, model_filename)\n    \n    # Calculate metrics\n    accuracy = accuracy_score(y_test, y_pred)\n    report = classification_report(y_test, y_pred, output_dict=True)\n    precision = report['macro avg']['precision']\n    recall = report['macro avg']['recall']\n    f1_score = report['macro avg']['f1-score']\n\n    # Create a temporary DataFrame and concatenate\n    temp_df = pd.DataFrame({\n        \"Model\": [name],\n        \"Accuracy\": [accuracy],\n        \"Precision\": [precision],\n        \"Recall\": [recall],\n        \"F1-Score\": [f1_score],\n        \"Training Time (s)\": [training_time]\n    })\n    results_df = pd.concat([results_df, temp_df], ignore_index=True)\n\n    # Print report\n    print(f\"{name} - Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1-Score: {f1_score}, Training Time: {training_time:.2f} seconds\")\n\n    # Confusion Matrix\n    cm = confusion_matrix(y_test, y_pred)\n    plt.figure(figsize=(10, 7))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Cyst', 'Normal', 'Stone', 'Tumor'],yticklabels=['Cyst', 'Normal', 'Stone', 'Tumor'])\n    plt.title(f'Confusion Matrix for {name}')\n    plt.ylabel('Actual')\n    plt.xlabel('Predicted')\n    plt.savefig(f\"confusion_matrix_{name}.png\")\n    plt.close()\n\n# Save results to CSV\nresults_df.to_csv('model_evaluation_results.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-26T16:24:51.206117Z","iopub.execute_input":"2023-12-26T16:24:51.207024Z","iopub.status.idle":"2023-12-26T16:37:21.586501Z","shell.execute_reply.started":"2023-12-26T16:24:51.206993Z","shell.execute_reply":"2023-12-26T16:37:21.585509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hyperparameter Tuning","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n","metadata":{"execution":{"iopub.status.busy":"2023-12-26T16:37:21.587721Z","iopub.execute_input":"2023-12-26T16:37:21.590312Z","iopub.status.idle":"2023-12-26T16:37:21.595284Z","shell.execute_reply.started":"2023-12-26T16:37:21.590278Z","shell.execute_reply":"2023-12-26T16:37:21.594207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hyperparameter grids for different classifiers\nparam_grids = {\n    \"Random Forest\": {\n        'n_estimators': [50, 100, 200],\n        'max_features': ['auto', 'sqrt', 'log2'],\n        'max_depth': [None, 10, 20, 30],\n        'min_samples_split': [2, 5, 10],\n        'min_samples_leaf': [1, 2, 4]\n    },\n    \"SVM\": {\n        'C': [0.1, 1, 10, 100],\n        'kernel': ['linear', 'rbf', 'poly'],\n        'gamma': ['scale', 'auto']\n    },\n    \"K-Nearest Neighbors\": {\n        'n_neighbors': [3, 5, 7, 9],\n        'weights': ['uniform', 'distance'],\n        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n    },\n    \"Naive Bayes\": {\n        'var_smoothing': np.logspace(0, -9, num=4)\n    },\n    \"Decision Tree\": {\n        'max_depth': [None, 10, 20, 30, 40],\n        'min_samples_split': [2, 5, 10],\n        'min_samples_leaf': [1, 2, 4]\n    },\n    \"Logistic Regression\": {\n        'C': [0.1, 1, 10, 100],\n        'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n        'max_iter': [100, 200, 300]\n    },\n    \"Gradient Boosting\": {\n        'n_estimators': [50, 100, 200],\n        'learning_rate': [0.01, 0.1, 0.2],\n        'max_depth': [3, 5, 10],\n        'min_samples_split': [2, 5],\n        'min_samples_leaf': [1, 2]\n    },\n    \"AdaBoost\": {\n        'n_estimators': [50, 100, 200],\n        'learning_rate': [0.01, 0.1, 1.0]\n    },\n    \"Extra Trees\": {\n        'n_estimators': [50, 100, 200],\n        'max_features': ['auto', 'sqrt', 'log2'],\n        'max_depth': [None, 10, 20, 30],\n        'min_samples_split': [2, 5, 10],\n        'min_samples_leaf': [1, 2, 4]\n    }\n}\n","metadata":{"execution":{"iopub.status.busy":"2023-12-26T16:37:21.596626Z","iopub.execute_input":"2023-12-26T16:37:21.597985Z","iopub.status.idle":"2023-12-26T16:37:21.610110Z","shell.execute_reply.started":"2023-12-26T16:37:21.597942Z","shell.execute_reply":"2023-12-26T16:37:21.608993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DataFrame to store results\nresults_df = pd.DataFrame(columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"Training Time (s)\"])\n\n# Train, evaluate each classifier with hyperparameter tuning, and save results\nfor name, clf in classifiers.items():\n    grid_search = GridSearchCV(estimator=clf, param_grid=param_grids[name], cv=3, n_jobs=-1, verbose=2)\n    \n    start_time = time.time()\n    grid_search.fit(X_train, y_train)\n    best_clf = grid_search.best_estimator_\n    training_time = time.time() - start_time\n    \n    print(f\"Total Training time for {name}_Hyperparameter_Tuning: {training_time:.2f} seconds\")\n\n    y_pred = best_clf.predict(X_test)\n    \n    # Save the trained model\n    model_filename = f\"{name.replace(' ', '_')}_model_Hyperparameter_Tuning.joblib\"\n    joblib.dump(best_clf, model_filename)\n    \n    # Calculate metrics\n    accuracy = accuracy_score(y_test, y_pred)\n    report = classification_report(y_test, y_pred, output_dict=True)\n    precision = report['macro avg']['precision']\n    recall = report['macro avg']['recall']\n    f1_score = report['macro avg']['f1-score']\n\n    # Create a temporary DataFrame and concatenate\n    temp_df = pd.DataFrame({\n        \"Model\": [name+\"_Hyperparameter_Tuning\"],\n        \"Accuracy\": [accuracy],\n        \"Precision\": [precision],\n        \"Recall\": [recall],\n        \"F1-Score\": [f1_score],\n        \"Training Time (s)\": [training_time]\n    })\n    results_df = pd.concat([results_df, temp_df], ignore_index=True)\n\n    # Print report\n    print(f\"{name}_Hyperparameter_Tuning - Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1-Score: {f1_score}, Training Time: {training_time:.2f} seconds\")\n\n    # Confusion Matrix\n    cm = confusion_matrix(y_test, y_pred)\n    plt.figure(figsize=(10, 7))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Cyst', 'Normal', 'Stone', 'Tumor'],yticklabels=['Cyst', 'Normal', 'Stone', 'Tumor'])\n    plt.title(f'Confusion Matrix for {name}')\n    plt.ylabel('Actual')\n    plt.xlabel('Predicted')\n    plt.savefig(f\"confusion_matrix_{name}_Hyperparameter_Tuning.png\")\n    plt.close()\n\n# Save results to CSV\nresults_df.to_csv('model_evaluation_results.csv', index=False)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-12-26T16:37:21.614537Z","iopub.execute_input":"2023-12-26T16:37:21.614872Z","iopub.status.idle":"2023-12-26T16:37:21.623617Z","shell.execute_reply.started":"2023-12-26T16:37:21.614844Z","shell.execute_reply":"2023-12-26T16:37:21.622777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.ensemble import VotingClassifier\n# import joblib\n\n# # List of your model names\n# model_names = [\"Random_Forest\", \"SVM\", \"K-Nearest_Neighbors\", \"Naive_Bayes\", \"Decision_Tree\", \"Logistic_Regression\", \"Gradient_Boosting\", \"AdaBoost\", \"Extra_Trees\"]\n\n# # Load the trained models\n# classifiers = {name: joblib.load(f\"{name}_model.joblib\") for name in model_names}\n\n# # Create ensemble classifiers\n# classifiers_for_voting = [(name, clf) for name, clf in classifiers.items()]\n\n# # Hard Voting Classifier\n# hard_voting_clf = VotingClassifier(estimators=classifiers_for_voting, voting='hard')\n# hard_voting_clf.fit(X_train, y_train)\n# y_pred_hard = hard_voting_clf.predict(X_test)\n\n# # Evaluate Hard Voting Classifier\n# hard_accuracy = accuracy_score(y_test, y_pred_hard)\n# print(\"Hard Voting Classifier Accuracy:\", hard_accuracy)\n\n# # Soft Voting Classifier\n# # Note: Ensure all classifiers support predict_proba for soft voting\n# soft_voting_clf = VotingClassifier(estimators=classifiers_for_voting, voting='soft')\n# soft_voting_clf.fit(X_train, y_train)\n# y_pred_soft = soft_voting_clf.predict(X_test)\n\n# # Evaluate Soft Voting Classifier\n# soft_accuracy = accuracy_score(y_test, y_pred_soft)\n# print(\"Soft Voting Classifier Accuracy:\", soft_accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-26T16:37:21.628272Z","iopub.execute_input":"2023-12-26T16:37:21.628845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import joblib\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.ensemble import VotingClassifier\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# Load the trained models\nmodel_names = [\"Random_Forest\", \"SVM\", \"K-Nearest_Neighbors\", \"Naive_Bayes\", \"Decision_Tree\", \"Logistic_Regression\", \"Gradient_Boosting\", \"AdaBoost\", \"Extra_Trees\"]\nclassifiers = {name: joblib.load(f\"{name}_model.joblib\") for name in model_names}\n\n# Create ensemble classifiers\nclassifiers_for_voting = [(name, clf) for name, clf in classifiers.items()]\n\n# Hard Voting Classifier\nhard_voting_clf = VotingClassifier(estimators=classifiers_for_voting, voting='hard')\nhard_voting_clf.fit(X_train, y_train)\ny_pred_hard = hard_voting_clf.predict(X_test)\n\n# Soft Voting Classifier\nsoft_voting_clf = VotingClassifier(estimators=classifiers_for_voting, voting='soft')\nsoft_voting_clf.fit(X_train, y_train)\ny_pred_soft = soft_voting_clf.predict(X_test)\n\n# DataFrame to store results\nresults_df = pd.DataFrame(columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"Training Time (s)\"])\n\n# Store results of hard voting\nhard_report = classification_report(y_test, y_pred_hard, output_dict=True)\nhard_df = pd.DataFrame({\n    \"Model\": [\"Hard Voting\"],\n    \"Accuracy\": [hard_report['accuracy']],\n    \"Precision\": [hard_report['macro avg']['precision']],\n    \"Recall\": [hard_report['macro avg']['recall']],\n    \"F1-Score\": [hard_report['macro avg']['f1-score']],\n    \"Training Time (s)\": [None]\n})\nresults_df = pd.concat([results_df, hard_df], ignore_index=True)\n\n# Store results of soft voting\nsoft_report = classification_report(y_test, y_pred_soft, output_dict=True)\nsoft_df = pd.DataFrame({\n    \"Model\": [\"Soft Voting\"],\n    \"Accuracy\": [soft_report['accuracy']],\n    \"Precision\": [soft_report['macro avg']['precision']],\n    \"Recall\": [soft_report['macro avg']['recall']],\n    \"F1-Score\": [soft_report['macro avg']['f1-score']],\n    \"Training Time (s)\": [None]\n})\n\n\nresults_df = pd.concat([results_df, soft_df], ignore_index=True)\n\n# Save results to CSV\nresults_df.to_csv('voting_classifier_results.csv', index=False)\n\n# Optionally, print the results\nprint(results_df)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save metrics to CSV file\ncsv_file = 'model_evaluation_results.csv'\nif not os.path.exists(csv_file):\n    results_df.to_csv(csv_file, index=False)\nelse:\n    pd.concat([pd.read_csv(csv_file), results_df]).to_csv(csv_file, index=False)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import StackingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n\n# Define base learners\nbase_learners = [\n    ('dt', DecisionTreeClassifier(random_state=42)),\n    ('knn', KNeighborsClassifier()),\n    ('svc', SVC(probability=True, random_state=42))\n]\n\n# Define meta-learner\nmeta_learner = ExtraTreesClassifier(n_estimators=100)\n\n# Stacking Classifier\nstacking_clf = StackingClassifier(estimators=base_learners, final_estimator=meta_learner, cv=5)\nstacking_clf.fit(X_train, y_train)\n\n# Make predictions and evaluate the model\ny_pred = stacking_clf.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'Stacking Model Accuracy: {accuracy:.4f}')\n# Store results of soft voting\nstacking_report = classification_report(y_test, y_pred, output_dict=True)\nstacking_df = pd.DataFrame({\n    \"Model\": [\"Stacking\"],\n    \"Accuracy\": [stacking_report['accuracy']],\n    \"Precision\": [stacking_report['macro avg']['precision']],\n    \"Recall\": [stacking_report['macro avg']['recall']],\n    \"F1-Score\": [stacking_report['macro avg']['f1-score']],\n    \"Training Time (s)\": [None]\n})\n\n# Save metrics to CSV file\ncsv_file = 'model_evaluation_results.csv'\nif not os.path.exists(csv_file):\n    stacking_df.to_csv(csv_file, index=False)\nelse:\n    pd.concat([pd.read_csv(csv_file), stacking_df]).to_csv(csv_file, index=False)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}